{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72909aec-742a-452b-a118-6c500790b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the basic spark library\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create an entry point to the PySpark Application\n",
    "# spark is our connection to the database \n",
    "spark = SparkSession.builder \\ \n",
    "      .master(\"local\") \\\n",
    "      .appName(\"MyFirstSparkApplication\") \\\n",
    "      .getOrCreate()\n",
    "# master contains the URL of your remote spark instance or 'local'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08722a3e-89c6-42ed-95b0-3d97e0ff0eb7",
   "metadata": {},
   "source": [
    "<h4>Resilient Distributed Dataset (RDD)</h4>\n",
    "<ul>\n",
    "    <li>Fault tolerant</li>\n",
    "    <li>Resilient</li>\n",
    "    <li>Immutable</li>\n",
    "    <li>Partitioned</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906fc50f-a3e1-4e13-b4e3-60a12abaabfc",
   "metadata": {},
   "source": [
    "<h4>Data Upload</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f617ed1-5bce-4e2f-9e7b-5a89161792d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data from a list  \n",
    "data = [(\"Margherita\", 5.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Basil\"]),\n",
    "        (\"Calzone\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Prosciutto Cotto\"])]\n",
    "\n",
    "# Create an RDD\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df7f8d-b127-4671-9f20-d8d6e2d2dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload list from a file\n",
    "rdd_2 = spark.sparkContext.textFile(\"menu.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f80f26-6a96-4da0-b1a8-787156ef7306",
   "metadata": {},
   "source": [
    "<h4>Dataframe Creation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ebb85c-13d4-4ab7-8f3f-f5e5534c6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataframe\n",
    "df_data = [(\"Margherita\", 5.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Basil\"]),\n",
    "        (\"Calzone\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Prosciutto Cotto\"]),\n",
    "        (\"Diavola\", 5.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Spicy Salame\"]),\n",
    "        (\"Prosciutto\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Prosciutto Cotto\"]),\n",
    "        (\"Speck & Brie\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Speck\", \"Brie\"]),\n",
    "        (\"Tonno & Cipolle\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Tuna\", \"Onions\"]),\n",
    "        (\"Fries\", 3.95, [\"Potatoes\"])]\n",
    "        \n",
    "columns = [\"Pizza Name\", \"Price\", \"Ingredients\"]\n",
    "df = spark.createDataFrame(data = df_data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e85e8b-cfa2-45a0-b88f-7cf3af1fa54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 20 elements of a dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db8f5c-fd71-4a78-9b94-09c2a2d3617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a DataFrame\n",
    "df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv(\"menu_csv.txt\")\n",
    "\n",
    "# Print detected \n",
    "df.printSchema()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df7837-91d6-4220-a23c-cfc04a71d790",
   "metadata": {},
   "source": [
    "<h4>Dataframes from RDDs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361785f-81cd-4039-91a0-1471891e816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the RDD into a Dataframe\n",
    "df_from_rdd = rdd.toDF()\n",
    "\n",
    "# Print the schema of the Dataframe\n",
    "df_from_rdd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755516e-a93f-40d7-8167-13c622ce6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the RDD into a Dataframe, specifying the columns\n",
    "columns = [\"Pizza Name\", \"Price\", \"Ingredients\"]\n",
    "df_from_rdd = rdd.toDF(columns)\n",
    "df_from_rdd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf942b-8160-4d82-8f4b-70321b01fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_from_rdd = spark.createDataFrame(rdd).toDF(*columns)\n",
    "df_from_rdd.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c4704-59d3-4f0f-9582-e2d9134ff1bf",
   "metadata": {},
   "source": [
    "<h4>Custom Dataframe</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfda87-f209-4aa2-b989-6cfd5aed57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, ArrayType\n",
    "\n",
    "#Createe the schema using StructField(Name, Type, Nullable)\n",
    "schema = StructType([ \\\n",
    "    StructField(\"Pizza Name\", StringType(), True), \\\n",
    "    StructField(\"Price\", FloatType(), True), \\\n",
    "    StructField(\"Ingredients\", ArrayType(StringType()), True) \\\n",
    "])\n",
    " \n",
    "df = spark.createDataFrame(data = df_data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991a58a-c4d8-48a7-9b74-f20267254efb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Organizing Data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741212ed-9671-4b45-abd1-dfd99021632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting depending on the fields (default = ascending order)\n",
    "df.sort(\"Price\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f8118-a616-43e4-b501-2d7e0cce34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# Sorting depending on the fields\n",
    "df.sort(col(\"Price\"), col(\"Pizza Name\")).show(truncate = False) # or use df.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857f478-be58-4acb-8235-99ffc5230879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting using orderBy\n",
    "df.orderBy(col(\"Price\"), col(\"Pizza Name\")).show(truncate = False) # in case of df.Pizza Name i cant use it\n",
    "# so i use the function col(\"Pizza Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c2b65-e3ab-4fd9-8538-07d0bb081ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expliciting the sorting (work the same with orderBy)\n",
    "df.sort(col(\"Price\").asc(), col(\"Pizza Name\").desc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e4b71-ac6c-4419-b26e-01c00e2a93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could also use raw SQL\n",
    "# No spoilers -> We'll see how to use it later on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc888070-3830-424b-be01-29dc552df799",
   "metadata": {},
   "source": [
    "<h4>Explode Arrays in Individual Rows</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11d458-11b0-4dd9-b0bf-9707c599fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode # its like unwind on mongodb \n",
    "# it splut the array into a lot of row with only one value of the array\n",
    "\n",
    "exploded_df = df.select(col(\"Pizza Name\"), df.Price, explode(df.Ingredients))\n",
    "exploded_df.printSchema()\n",
    "exploded_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbc7d0-ee23-4c83-99be-4d1d15523f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can we rename a column?\n",
    "exploded_df = exploded_df.withColumnRenamed(\"col\", \"Ingredient\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e0216-5899-4264-8045-04af6320f138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_gpu_1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b33ec90f071c03324cc4a00b85f1e07ef984b0c9e8c529e6d6de6bb9edbc927"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
