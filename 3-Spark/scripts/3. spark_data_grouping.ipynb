{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7938b-f42b-4f2d-9780-ee73a36bf60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the basic spark library\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create an entry point to the PySpark Application\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local\") \\\n",
    "      .appName(\"MyFirstSparkApplication\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148cdf03-a8fa-42c7-b113-c4b206f213d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, ArrayType\n",
    "\n",
    "#Createe the schema using StructField(Name, Type, Nullable)\n",
    "schema = StructType([ \\\n",
    "    StructField(\"Pizza Name\", StringType(), True), \\\n",
    "    StructField(\"Price\", FloatType(), True), \\\n",
    "    StructField(\"Ingredients\", ArrayType(StringType()), True) \\\n",
    "])\n",
    "\n",
    "df_data = [(\"Margherita\", 5.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Basil\"]),\n",
    "        (\"Calzone\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Prosciutto Cotto\"]),\n",
    "        (\"Diavola\", 5.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Spicy Salame\"]),\n",
    "        (\"Prosciutto\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Prosciutto Cotto\"]),\n",
    "        (\"Speck & Brie\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Speck\", \"Brie\"]),\n",
    "        (\"Tonno & Cipolle\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Tuna\", \"Onions\"]),\n",
    "        (\"Fries\", 3.95, [\"Potatoes\"])]\n",
    "\n",
    "df = spark.createDataFrame(data = df_data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7401b-38e2-4fbf-a69e-e34fcfadc764",
   "metadata": {},
   "source": [
    "<h4>Grouping using groupBy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c275c5-89d1-4fd4-911a-08f5874b38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count\n",
    "df.groupBy(\"Price\").count().show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0a4a7-3260-4ac1-a83e-9db36932d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum\n",
    "df.groupBy().min(\"Price\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbcf3b8-5b76-432f-828e-f5ea9fbf3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average\n",
    "df.groupBy().avg(\"Price\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e2559e-ef28-42c3-bbf8-06e0e9671679",
   "metadata": {},
   "source": [
    "<h4>Grouping Multiple Columns</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda12b6-64ca-4765-ab55-c46e9d4f2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explode our array to perform more interesting operations\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "exploded_df = df.select(col(\"Pizza Name\"), df.Price, explode(df.Ingredients))\n",
    "exploded_df = exploded_df.withColumnRenamed(\"col\", \"Ingredient\")\n",
    "exploded_df.printSchema()\n",
    "exploded_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a836aa71-43c1-432f-a265-480b594bdacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting\n",
    "exploded_df.groupBy(\"Ingredient\", \"Price\").count().show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc6d797-6e92-476b-adc8-69a498e5f018",
   "metadata": {},
   "source": [
    "<h4>Multiple Aggregations</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8447a1-ba9b-4032-8e48-522fda2c3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, avg, count, max\n",
    "\n",
    "exploded_df.groupBy(\"Pizza Name\").agg(\n",
    "    sum(\"Price\").alias(\"Sum Price\"),\n",
    "    avg(\"Price\").alias(\"Average Price\"),\n",
    "    count(\"Ingredient\").alias(\"Number of Ingredients\"),\n",
    "    max(\"Price\").alias(\"Price\")).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941ed75-a2c3-413b-a6b2-22339a15d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep only the Pizza's with at least four ingredients\n",
    "exploded_df.groupBy(\"Pizza Name\") \\\n",
    "    .agg(count(\"Ingredient\").alias(\"Number of Ingredients\")) \\\n",
    "    .filter(col(\"Number of Ingredients\") >= 4) \\\n",
    "    .show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8fc369-a1ba-4358-9c27-e5c7cb732fb7",
   "metadata": {},
   "source": [
    "<h4>Aggregate Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de799bee-1ead-4e71-bc97-b3b29a090066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "\n",
    "# Count the number of unique values in a field\n",
    "print(\"Number of different ingredients\", str(exploded_df.select(approx_count_distinct(\"Ingredient\")).collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0014a-5a6e-4e13-9a04-1bdaa082eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Compute the average price for a Pizza\n",
    "print(\"Average Price: \", str(df.select(avg(\"Price\")).collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e3904-3343-4a43-846f-e5ca70c65326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "\n",
    "# Return all the values from a column (with duplicates)\n",
    "exploded_df.select(collect_list(\"Ingredient\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d37e1-8a76-4f43-a10a-f512c38404a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df.select(collect_list(\"Ingredient\")).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899f365-ef66-4925-baf4-d0eddfe5ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_set\n",
    "\n",
    "# Return all the values from a column (without duplicates)\n",
    "exploded_df.select(collect_set(\"Ingredient\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8464cc71-74df-4f36-9ffc-2f3635d0dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Return all the values from a column (without duplicates)\n",
    "exploded_df.select(countDistinct(\"Ingredient\", \"Price\")).withColumnRenamed(\"count(DISTINCT Ingredient, Price)\", \"count\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb82ff1f-8d7a-452b-b40b-ef115c8369ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import first, last\n",
    "\n",
    "# Select the first non-null element of the column\n",
    "df.select(first(\"Ingredients\")).show(truncate = False)\n",
    "\n",
    "# Select the last non-null element of the column\n",
    "df.select(last(\"Ingredients\")).show(truncate = False)\n",
    "\n",
    "# A wide variety of functions is also available, like avg(), sum(), mean(), variance(), stddev(), etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_gpu_1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b33ec90f071c03324cc4a00b85f1e07ef984b0c9e8c529e6d6de6bb9edbc927"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
