{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72909aec-742a-452b-a118-6c500790b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the basic spark library\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create an entry point to the PySpark Application\n",
    "# spark is our connection to the database \n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local\") \\\n",
    "      .appName(\"MyFirstSparkApplication\") \\\n",
    "      .getOrCreate()\n",
    "# master contains the URL of your remote spark instance or 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "599eea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- orcid: string (nullable = true)\n",
      " |-- month_of_birth: integer (nullable = true)\n",
      " |-- year_of_birth: integer (nullable = true)\n",
      " |-- mail: string (nullable = true)\n",
      "\n",
      "+--------------------+-------------------+--------------+-------------+--------------------+\n",
      "|                name|              orcid|month_of_birth|year_of_birth|                mail|\n",
      "+--------------------+-------------------+--------------+-------------+--------------------+\n",
      "|       Gilles Guette|9404-5450-4767-7840|             6|         1985|    iwAaxsL@duck.com|\n",
      "|      Renaud Pacalet|2886-4313-9155-9063|            12|         1952|      mAgIX@duck.com|\n",
      "|       Hak-Keung Lam|2629-3989-5026-3274|             6|         1942|     maGyVg@duck.com|\n",
      "|Sebastian J. F. F...|0000-0002-3553-5131|             7|         1977|  utqmZOW@outlook.it|\n",
      "|      Cristiana Amza|6548-4280-5081-9705|             6|         1949|   WcmIhU@outlook.it|\n",
      "|   Afshan Nourizadeh|2570-5168-4862-2639|             2|         1956|  giwnbEe@tiscali.it|\n",
      "|Willem-Jan van de...|7290-9549-8348-3983|             4|         1960|ApUoi@mail.polimi.it|\n",
      "|        Arthur Foltz|8539-1372-8582-8655|             1|         1942|      wDxwh@duck.com|\n",
      "|Luis M. Camarinha...|0000-0003-0594-1961|             4|         1972|  FtdSUPD@outlook.it|\n",
      "|      Sebastian Görg|7498-1590-5157-2600|             1|         1966|zfBvpEX@mail.poli...|\n",
      "|  Dominique Borrione|7922-6334-9671-0591|             4|         1980|  nvcLzAj@outlook.it|\n",
      "|    Stefan Gudenkauf|7632-0239-5194-6724|             7|         1957|      AbfQY@duck.com|\n",
      "|          Noura Faci|0452-9872-8161-3093|             7|         1964|    OJRDf@tiscali.it|\n",
      "|    Alexander Schill|9923-3230-7677-1123|             4|         1959|uAtrG@mail.polimi.it|\n",
      "|    Françoise Fabret|2097-0916-5700-8606|             8|         1951|   edQbwgb@gmail.com|\n",
      "|        Wei Ren 0001|4636-3343-7197-3487|             4|         1955|  dzxWlYG@outlook.it|\n",
      "|   Yoshiaki Sugiyama|5106-7368-4109-6482|             4|         1952|TEjsV@mail.polimi.it|\n",
      "|Moulay Driss Mech...|0000-0001-7480-2071|             9|         1951|     yLLeV@gmail.com|\n",
      "|         Werner Emde|8145-8429-0074-4052|             6|         1973|   pVASnM@tiscali.it|\n",
      "|    Geoffrey Simmons|5316-5762-8534-1049|            12|         1967|    ElwZvR@gmail.com|\n",
      "+--------------------+-------------------+--------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load a DataFrame\n",
    "df = spark.read.option(\"header\", True).option(\"delimiter\", \"|\").option(\"inferSchema\",True).csv(\"dataset/author.csv\")\n",
    "\n",
    "# Print detected \n",
    "df.printSchema()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08722a3e-89c6-42ed-95b0-3d97e0ff0eb7",
   "metadata": {},
   "source": [
    "<h4>Resilient Distributed Dataset (RDD)</h4>\n",
    "<ul>\n",
    "    <li>Fault tolerant</li>\n",
    "    <li>Resilient</li>\n",
    "    <li>Immutable</li>\n",
    "    <li>Partitioned</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906fc50f-a3e1-4e13-b4e3-60a12abaabfc",
   "metadata": {},
   "source": [
    "<h4>Data Upload</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f617ed1-5bce-4e2f-9e7b-5a89161792d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data from a list  \n",
    "data = [(\"Margherita\", 5.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Basil\"]),\n",
    "        (\"Calzone\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Prosciutto Cotto\"])]\n",
    "\n",
    "# Create an RDD\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df7f8d-b127-4671-9f20-d8d6e2d2dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload list from a file\n",
    "rdd_2 = spark.sparkContext.textFile(\"menu.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f80f26-6a96-4da0-b1a8-787156ef7306",
   "metadata": {},
   "source": [
    "<h4>Dataframe Creation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ebb85c-13d4-4ab7-8f3f-f5e5534c6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataframe\n",
    "df_data = [(\"Margherita\", 5.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Basil\"]),\n",
    "        (\"Calzone\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Prosciutto Cotto\"]),\n",
    "        (\"Diavola\", 5.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Spicy Salame\"]),\n",
    "        (\"Prosciutto\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Prosciutto Cotto\"]),\n",
    "        (\"Speck & Brie\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Speck\", \"Brie\"]),\n",
    "        (\"Tonno & Cipolle\", 7.95, [\"Tomato Sauce\", \"Mozzarella Cheese\", \"Tuna\", \"Onions\"]),\n",
    "        (\"Fries\", 3.95, [\"Potatoes\"])]\n",
    "        \n",
    "columns = [\"Pizza Name\", \"Price\", \"Ingredients\"]\n",
    "df = spark.createDataFrame(data = df_data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e85e8b-cfa2-45a0-b88f-7cf3af1fa54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 20 elements of a dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db8f5c-fd71-4a78-9b94-09c2a2d3617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a DataFrame\n",
    "df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv(\"menu_csv.txt\")\n",
    "\n",
    "# Print detected \n",
    "df.printSchema()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df7837-91d6-4220-a23c-cfc04a71d790",
   "metadata": {},
   "source": [
    "<h4>Dataframes from RDDs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361785f-81cd-4039-91a0-1471891e816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the RDD into a Dataframe\n",
    "df_from_rdd = rdd.toDF()\n",
    "\n",
    "# Print the schema of the Dataframe\n",
    "df_from_rdd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755516e-a93f-40d7-8167-13c622ce6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the RDD into a Dataframe, specifying the columns\n",
    "columns = [\"Pizza Name\", \"Price\", \"Ingredients\"]\n",
    "df_from_rdd = rdd.toDF(columns)\n",
    "df_from_rdd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf942b-8160-4d82-8f4b-70321b01fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_from_rdd = spark.createDataFrame(rdd).toDF(*columns)\n",
    "df_from_rdd.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c4704-59d3-4f0f-9582-e2d9134ff1bf",
   "metadata": {},
   "source": [
    "<h4>Custom Dataframe</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfda87-f209-4aa2-b989-6cfd5aed57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, ArrayType\n",
    "\n",
    "#Createe the schema using StructField(Name, Type, Nullable)\n",
    "schema = StructType([ \\\n",
    "    StructField(\"Pizza Name\", StringType(), True), \\\n",
    "    StructField(\"Price\", FloatType(), True), \\\n",
    "    StructField(\"Ingredients\", ArrayType(StringType()), True) \\\n",
    "])\n",
    " \n",
    "df = spark.createDataFrame(data = df_data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991a58a-c4d8-48a7-9b74-f20267254efb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Organizing Data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741212ed-9671-4b45-abd1-dfd99021632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting depending on the fields (default = ascending order)\n",
    "df.sort(\"Price\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f8118-a616-43e4-b501-2d7e0cce34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# Sorting depending on the fields\n",
    "df.sort(col(\"Price\"), col(\"Pizza Name\")).show(truncate = False) # or use df.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857f478-be58-4acb-8235-99ffc5230879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting using orderBy\n",
    "df.orderBy(col(\"Price\"), col(\"Pizza Name\")).show(truncate = False) # in case of df.Pizza Name i cant use it\n",
    "# so i use the function col(\"Pizza Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c2b65-e3ab-4fd9-8538-07d0bb081ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expliciting the sorting (work the same with orderBy)\n",
    "df.sort(col(\"Price\").asc(), col(\"Pizza Name\").desc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e4b71-ac6c-4419-b26e-01c00e2a93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could also use raw SQL\n",
    "# No spoilers -> We'll see how to use it later on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc888070-3830-424b-be01-29dc552df799",
   "metadata": {},
   "source": [
    "<h4>Explode Arrays in Individual Rows</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11d458-11b0-4dd9-b0bf-9707c599fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode # its like unwind on mongodb \n",
    "# it splut the array into a lot of row with only one value of the array\n",
    "\n",
    "exploded_df = df.select(col(\"Pizza Name\"), df.Price, explode(df.Ingredients))\n",
    "exploded_df.printSchema()\n",
    "exploded_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbc7d0-ee23-4c83-99be-4d1d15523f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can we rename a column?\n",
    "exploded_df = exploded_df.withColumnRenamed(\"col\", \"Ingredient\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e0216-5899-4264-8045-04af6320f138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
